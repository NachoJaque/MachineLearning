{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrantes: Ignacio Jaque y Owens Lopez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente trabajo se utilizara el modelo CRISP-DM para solucionar un problema que incluya el analisis de letras escritas a mano.\n",
    "\n",
    "# Comprensión del Negocio\n",
    "\n",
    "### Problema:\n",
    "Una empresa de desarrollo de software para educación está buscando una herramienta innovadora que facilite el aprendizaje y práctica de la escritura en niños. Uno de sus desafíos es proporcionar un sistema de retroalimentación en tiempo real que permita a los estudiantes escribir letras a mano y recibir una evaluación sobre su exactitud y claridad en comparación con un estándar ideal. Este sistema ayudaría a identificar patrones de escritura inusuales o errores comunes en las letras.\n",
    "\n",
    "### Objetivos:\n",
    "1. Crear un modelo de reconocimiento de caracteres manuscritos que pueda clasificar con precisión letras escritas a mano, incluso con variaciones comunes entre diferentes estilos de escritura.\n",
    "2. Desarrollar un dataset de letras escritas a mano que incluya ejemplos variados, idealmente de distintos estilos y caligrafías, para entrenar al modelo.\n",
    "3. Implementar métricas de evaluación y retroalimentación que permitan medir el rendimiento del modelo en tiempo real, con un enfoque en precisión y velocidad.\n",
    "4. Crear un sistema de evaluación automática que identifique patrones de error frecuentes en las letras, facilitando sugerencias de mejora para los estudiantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprensión de los Datos\n",
    "\n",
    "### Exploración de los Datos: \n",
    "Los datos corresponden a imagenes de letras escritas a mano de todo el abecedario, estas seran pasadas a un tamaño de 28x28 pixeles para conseguir que todas sean uniformes para el análisis.\n",
    "Los datos corresponden entonces a las 27 letras del abecedario (incluye la ñ) escritas por distintas personas para poder obtener un rango mas amplio de formas de escribir.\n",
    "\n",
    "De igual manera se etiquetaran todas las imagenes, asignando el valor de la letra a la que representan en el abecedario (0 para la A, 1 para la B, etc)\n",
    "\n",
    "QUIZAS AQUI AÑADIR EL DETALLE DE VERIFICAR QUE NO FALTEN DATOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación de los Datos.\n",
    "\n",
    "### Limpieza y Transformación:\n",
    "En esta etapa se transformaran las imagenes para poder ser trabajadas en el modelo, para esto se realizaran los siguientes pasos:\n",
    "* Recorte y Redimensionamiento de Imágenes: Como ya se ha definido, cada imagen recortada de la letra debe ser redimensionada a una matriz de 28x28 píxeles para mantener la uniformidad del dataset. Esto también simplifica el entrenamiento al convertir cada imagen a un formato consistente y manejable.\n",
    "* Conversión a Escala de Grises: Asegúrate de que cada imagen esté en escala de grises, lo que reduce la complejidad y elimina el impacto de cualquier variación de color o iluminación que pueda afectar el reconocimiento de las letras.\n",
    "* Conversión a Vectores Aplanados: Una vez redimensionadas, cada imagen 28x28 se convierte en un vector de 784 elementos. Esta representación es compatible con la entrada de redes neuronales densas, como en el caso del modelo ajustado para Fashion MNIST.\n",
    "\n",
    "### Detección y manejo de Outliers\n",
    "Es necesario verificar que no hayan entradas que ppuedan arruinar los resultados, por eso revisamos los outliers:\n",
    "\n",
    "* Identificación de Outliers Visuales: Explora ejemplos de cada letra para identificar imágenes que podrían ser outliers, como letras incompletas, borrosas o de difícil interpretación, que puedan confundir al modelo.\n",
    "* Manejo de Outliers: Si encuentras ejemplos que claramente no representan bien la letra etiquetada, puedes eliminarlos del dataset o, si el número de ejemplos incorrectos es muy bajo, etiquetarlos correctamente o reemplazarlos por otras muestras válidas. Esto asegura que el modelo no aprenda patrones erróneos.\n",
    "\n",
    "### División del Dataset\n",
    "Una vez estamos seguros de la veracidad de los datos, procedemos a dividir el dataset en 2 partes, una para el entrenamiento y otra para las pruebas:\n",
    "* División en Conjunto de Entrenamiento y Prueba: Generalmente, se utiliza un 80% del dataset para entrenamiento y un 20% para pruebas. Esto permite evaluar el rendimiento del modelo con datos no vistos y ajustar hiperparámetros."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
